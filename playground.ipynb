{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d1dab7f1bc4641833223e03c3216e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"bigcode/starcoderdata\", data_dir=\"html\", split=\"train[:100]\", cache_dir=\"/mnt/disks/venus_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 14790.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for instance in tqdm(ds):\n",
    "    print(instance['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def append_dicts_to_csv(file_path, dict_list, fieldnames):\n",
    "    \"\"\"\n",
    "    Append a list of dictionaries to a CSV file.\n",
    "\n",
    "    :param file_path: Path to the CSV file\n",
    "    :param dict_list: List of dictionaries to append\n",
    "    :param fieldnames: List of field names (CSV header)\n",
    "    \"\"\"\n",
    "    # Open the file in append mode\n",
    "    with open(file_path, mode='a', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # If the file is empty, write the header\n",
    "        csv_file.seek(0, 2)  # Move the cursor to the end of the file\n",
    "        if csv_file.tell() == 0:\n",
    "            writer.writeheader()\n",
    "\n",
    "        # Write the rows\n",
    "        for data_dict in dict_list:\n",
    "            writer.writerow(data_dict)\n",
    "\n",
    "# Example usage\n",
    "file_path = 'output.csv'\n",
    "dict_list = [\n",
    "    {'name': 'Alice', 'age': 30, 'city': 'New York'},\n",
    "    {'name': 'Bob', 'age': 25, 'city': 'San Francisco'},\n",
    "]\n",
    "fieldnames = ['name', 'age', 'city']\n",
    "\n",
    "append_dicts_to_csv(file_path, dict_list, fieldnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = list()\n",
    "\n",
    "for i in range(10):\n",
    "    mock_data += [\n",
    "        {\n",
    "            \"problem_description\": \"lalala\",\n",
    "            \"test_case_generator\": \"lalala\",\n",
    "            \"test_cases\": \"lalala\",\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.Dataset.from_list(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db72af6fcf1e44acb6dd6aeab11c29a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23533859fb546e1ab2b5d5f6fc8d50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Elfsong/Venus/commit/2b918f6f884594741c6e718364d7459be26782d7', commit_message='Upload dataset', commit_description='', oid='2b918f6f884594741c6e718364d7459be26782d7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"Elfsong/Venus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import memray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Memray WARNING: Correcting symbol for aligned_alloc from 0x7fc3f86575e0 to 0x7fc40ce52550\n"
     ]
    }
   ],
   "source": [
    "with memray.Tracker(\"output.bin\"):\n",
    "    def fibonacci(length):\n",
    "        # edge cases\n",
    "        if length < 1:\n",
    "            return []\n",
    "        if length == 1:\n",
    "            return [1]\n",
    "        if length == 2:\n",
    "            return [1, 1]\n",
    "\n",
    "        output = [1, 1]\n",
    "\n",
    "        for i in range(length - 2):\n",
    "            output.append(output[i] + output[i + 1])  # <- Here!\n",
    "\n",
    "        return output\n",
    "    \n",
    "    fibonacci(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 3799 bytes\n"
     ]
    }
   ],
   "source": [
    "from guppy import hpy\n",
    "\n",
    "h = hpy()\n",
    "heap_status1 = h.heap()\n",
    "\n",
    "def my_function():\n",
    "    a = [1] * 10000000\n",
    "    b = [0] * 2000000\n",
    "    return a, b\n",
    "\n",
    "my_function()\n",
    "\n",
    "heap_status2 = h.heap()\n",
    "\n",
    "print(f\"Memory used: {heap_status2.size - heap_status1.size} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current memory usage: 0.001 MB; Peak: 80.00061 MB\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "\n",
    "def my_function():\n",
    "    a = [0] * 10000000\n",
    "    return a\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "my_function()\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "print(f\"Current memory usage: {current / 10**6} MB; Peak: {peak / 10**6} MB\")\n",
    "\n",
    "tracemalloc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Elfsong/Afterburner_code_correction\", \"469c00b0-6c2d-11ef-a1aa-42010a94000c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'code_mem': None,\n",
       "   'code_time': None,\n",
       "   'content': 'You are a code expert. Generate pure code for code fields.',\n",
       "   'label': 'system_prompt',\n",
       "   'mem': None,\n",
       "   'role': 'system',\n",
       "   'status': None,\n",
       "   'time': None,\n",
       "   'traceback': None},\n",
       "  {'code_mem': None,\n",
       "   'code_time': None,\n",
       "   'content': 'Given the problem and the test case generator, generate a Python Solution.\\nProblem: You need to create a function that parses a blog post metadata and body from a provided text input. The input will be a string containing the metadata and body of a blog post in the following format:\\\\n```\\\\nprefix = \"/\"\\\\n\\\\nif language is None: \\\\n    qs_lang = doc.query.getfirst(\"lang\")\\\\n    if qs_lang and qs_lang in [\"en\", \"fr\", \"es\"]: \\\\n        has_req = Truetitle: My Fifth Post\\\\nexcerpt: Lorem, ipsum dolor sit amet consectetur adipisicing elit.\\\\ndate: 2021-07-07\\\\nslug: my-fourth-post\\\\n---\\\\n\\\\n<p>\\\\n    Lorem, ipsum dolor sit amet consectetur adipisicing elit. Molestias maiores ullam quia! Eaque esse, possimus cum voluptatum aliquid, laborum, a similique fugiat non suscipit quisquam architecto incidunt tempora veritatis ipsa?\\\\n```\\\\n\\\\nYour task is to extract the metadata and body. The metadata includes the title, excerpt, date, and slug. The body includes the HTML content. Return the metadata and body in a tuple.\\\\n\\\\n__Input__:\\\\n- A single string containing the blog post metadata and body.\\\\n\\\\n__Output__:\\\\n- A tuple containing the metadata (as a dictionary) and the body (as a string).\\\\n\\\\n__Example__:\\\\n```\\\\nInput: \\'title: My Fifth Post\\\\nexcerpt: Lorem, ipsum dolor sit amet consectetur adipisicing elit.\\\\ndate: 2021-07-07\\\\nslug: my-fourth-post\\\\n---\\\\n\\\\n<p>\\\\n    Lorem, ipsum dolor sit amet consectetur adipisicing elit. Molestias maiores ullam quia! Eaque esse, possimus cum voluptatum aliquid, laborum, a similique fugiat non suscipit quisquam architecto incidunt tempora veritatis ipsa?\\\\n\\'\\\\n\\\\nOutput: ({\\'title\\': \\'My Fifth Post\\', \\'excerpt\\': \\'Lorem, ipsum dolor sit amet consectetur adipisicing elit.\\', \\'date\\': \\'2021-07-07\\', \\'slug\\': \\'my-fourth-post\\'}, \\'<p>\\\\n    Lorem, ipsum dolor sit amet consectetur adipisicing elit. Molestias maiores ullam quia! Eaque esse, possimus cum voluptatum aliquid, laborum, a similique fugiat non suscipit quisquam architecto incidunt tempora veritatis ipsa?\\\\n\\')\\\\n```\\nTest Case Generator: import random\\n\\ndef generate_test_case():\\n    titles = [\"My First Post\", \"Another Great Post\", \"Yet Another Post\"]\\n    excerpts = [\"This is an excerpt.\", \"Another excerpt.\", \"More excerpts.\"]\\n    dates = [\"2021-01-01\", \"2021-06-15\", \"2021-12-31\"]\\n    slugs = [\"my-first-post\", \"another-great-post\", \"yet-another-post\"]\\n    bodies = [\"<p>Content of the first post.</p>\", \"<p>Content of another post.</p>\", \"<p>Yet more content.</p>\"]\\n\\n    title = random.choice(titles)\\n    excerpt = random.choice(excerpts)\\n    date = random.choice(dates)\\n    slug = random.choice(slugs)\\n    body = random.choice(bodies)\\n\\n    meta_data = f\\'title: {title}\\\\nexcerpt: {excerpt}\\\\ndate: {date}\\\\nslug: {slug}\\\\n---\\\\n\\\\n\\'\\n    return (meta_data + body,)\\n',\n",
       "   'label': 'problem',\n",
       "   'mem': None,\n",
       "   'role': 'user',\n",
       "   'status': None,\n",
       "   'time': None,\n",
       "   'traceback': None},\n",
       "  {'code_mem': 7449613.0,\n",
       "   'code_time': 0.0063250064849853516,\n",
       "   'content': \"def parse_blog_post(text):\\n    metadata_end_idx = text.find('---')\\n    metadata_lines = text[:metadata_end_idx].strip().split('\\\\n')\\n    metadata = {}\\n    for line in metadata_lines:\\n        key, value = line.split(': ', 1)\\n        metadata[key.strip()] = value.strip()\\n    body = text[metadata_end_idx+3:].strip()\\n    return metadata, body\",\n",
       "   'label': 'solution',\n",
       "   'mem': None,\n",
       "   'role': 'assistant',\n",
       "   'status': 'success',\n",
       "   'time': None,\n",
       "   'traceback': 'None'}],\n",
       " 'entry_point': 'parse_blog_post',\n",
       " 'test_case_generator': 'import random\\n\\ndef generate_test_case():\\n    titles = [\"My First Post\", \"Another Great Post\", \"Yet Another Post\"]\\n    excerpts = [\"This is an excerpt.\", \"Another excerpt.\", \"More excerpts.\"]\\n    dates = [\"2021-01-01\", \"2021-06-15\", \"2021-12-31\"]\\n    slugs = [\"my-first-post\", \"another-great-post\", \"yet-another-post\"]\\n    bodies = [\"<p>Content of the first post.</p>\", \"<p>Content of another post.</p>\", \"<p>Yet more content.</p>\"]\\n\\n    title = random.choice(titles)\\n    excerpt = random.choice(excerpts)\\n    date = random.choice(dates)\\n    slug = random.choice(slugs)\\n    body = random.choice(bodies)\\n\\n    meta_data = f\\'title: {title}\\\\nexcerpt: {excerpt}\\\\ndate: {date}\\\\nslug: {slug}\\\\n---\\\\n\\\\n\\'\\n    return (meta_data + body,)\\n'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
